{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1t_OEDwK2zqr3PLzPeYB66fxhYnTxwNE9",
      "authorship_tag": "ABX9TyODFVW6aUnohgDGkD7dlv53",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achintya-7/Brain-Tumor-Segmentation/blob/main/Brain_Tumor_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNET\n",
        "\n",
        "The architecture for UNET is as following\n",
        "\n",
        "![U-Net Architecture](https://raw.githubusercontent.com/achintya-7/Brain-Tumor-Segmentation/main/model/media/img/u-net-architecture.png)"
      ],
      "metadata": {
        "id": "_nPqaMeN1d3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary packages from tensorflow"
      ],
      "metadata": {
        "id": "Tf9c1V3JGvsS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4tSfAdsj1RFF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining all the layers of unet as per the diagram"
      ],
      "metadata": {
        "id": "DD2vlXl521Ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conv_block\n",
        "1. Conv2D: This is a 2D convolution layer, which is a fundamental component of convolutional neural networks (CNNs). It applies a number of convolution operations on the input. The number of these operations is defined by the number of filters. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The transformation is applied on the whole image.\n",
        "\n",
        "2. BatchNormalization: This is a technique to improve the performance and stability of neural networks by normalizing the inputs in every layer. It reduces the amount the hidden unit values shift around (covariate shift). In other words, it helps each layer of a network to learn by itself a little more independently of other layers.\n",
        "\n",
        "3. Activation: An activation function defines the output of a neuron given an input or set of inputs. In this case, 'relu' (Rectified Linear Unit) is used as the activation function. The ReLU function is f(x) = max(0, x), where x is the input. It sets all negative values in the matrix x to 0 and keeps all the other values the same.\n",
        "\n",
        "The conv_block function applies two sets of these layers (Conv2D -> BatchNormalization -> Activation) sequentially. This is a common architecture for a block in a convolutional neural network. The function takes as input a tensor (multi-dimensional array) and the number of filters for the Conv2D layers, and returns the output tensor after applying these operations."
      ],
      "metadata": {
        "id": "SAsj5QaEG0yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "wDzg6pjlHC1r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Block\n",
        "\n",
        "1. x = conv_block(inputs, num_filters): This line applies the conv_block function to the inputs. The conv_block function consists of two sets of Conv2D -> BatchNormalization -> Activation layers. The output of this operation is stored in x.\n",
        "\n",
        "2. p = MaxPool2D((2, 2))(x): This line applies a 2D max pooling operation to the output of the conv_block. Max pooling is a downsampling strategy that selects the maximum value from a region of the input. In this case, the region size is 2x2. The output of this operation is stored in p.\n",
        "\n",
        "3. return x, p: The function returns two tensors. The first tensor x is the output of the conv_block (before pooling). This will be used later in the \"upsampling\" or \"expansion\" part of the network for the skip connections. The second tensor p is the output of the MaxPool2D layer. This will be the input to the next encoder_block in the network.\n",
        "\n",
        "In the context of the U-Net architecture, the purpose of the encoder_block is to extract features from the input image at different scales and to reduce the spatial dimensions of the input for the next encoder_block."
      ],
      "metadata": {
        "id": "MSOfVdBsHF2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p"
      ],
      "metadata": {
        "id": "cF33G4rF2vIY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder Block\n",
        "\n",
        "1. x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(inputs): This line applies a Conv2DTranspose operation to the inputs. Conv2DTranspose is often referred to as deconvolution in the context of CNNs. It performs an inverse convolution operation, which increases the spatial dimensions of the input. The number of filters, kernel size, and stride are specified as parameters.\n",
        "\n",
        "2. x = Concatenate()([x, skip_features]): This line concatenates the upsampled tensor x and the corresponding tensor from the encoder path (skip_features). This is known as a skip connection, which helps to recover the spatial information lost during encoding.\n",
        "\n",
        "3. x = conv_block(x, num_filters): This line applies the conv_block function to the concatenated tensor. The conv_block function consists of two sets of Conv2D -> BatchNormalization -> Activation layers.\n",
        "\n",
        "4. return x: The function returns the output tensor, which will be the input to the next decoder_block in the network or the final output layer of the network.\n",
        "\n",
        "In the context of the U-Net architecture, the purpose of the decoder_block is to upsample the feature map and concatenate it with the correspondingly downsampled feature map from the encoding path. This helps to recover the spatial information and details lost during the encoding process."
      ],
      "metadata": {
        "id": "PrZqPRQvM1dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x"
      ],
      "metadata": {
        "id": "b9u7gcHALjsa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Build Up\n",
        "1. inputs = Input(input_shape): This line creates an input layer with the given shape.\n",
        "\n",
        "2. The next four lines (s1, p1 = encoder_block(inputs, 64) and so on) define the encoder path of the U-Net. Each encoder_block consists of a convolutional block followed by a MaxPool2D layer for downsampling. The function returns two tensors: the output of the convolutional block (before pooling) and the output of the MaxPool2D layer.\n",
        "\n",
        "3. b1 = conv_block(p4, 1024): This line defines the bottleneck of the U-Net, which is a convolutional block at the bottom of the U.\n",
        "\n",
        "4. The next four lines (d1 = decoder_block(b1, s4, 512) and so on) define the decoder path of the U-Net. Each decoder_block consists of a Conv2DTranspose layer for upsampling, a concatenation of the upsampled tensor and the corresponding tensor from the encoder path (skip connection), and a convolutional block.\n",
        "\n",
        "5. outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4): This line defines the output layer of the U-Net. It's a Conv2D layer with a sigmoid activation function, which is commonly used for binary classification problems.\n",
        "\n",
        "6. model = Model(inputs, outputs, name=\"UNET\"): This line creates a Keras Model instance with the given inputs and outputs.\n",
        "\n",
        " The purpose of the build_unet function is to construct the U-Net model with the specified input shape. The U-Net model is a type of convolutional neural network that is particularly effective for image segmentation tasks."
      ],
      "metadata": {
        "id": "-NgzIYMlLf9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "SeAHzTqm3JWl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (256, 256, 3)\n",
        "model = build_unet(input_shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qbxf46zP3lrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01fca1c-a265-42d5-d42e-8df454063a38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 64)         1792      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 32, 32, 512)          2097664   ['activation_9[0][0]']        \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 32, 32, 1024)         0         ['conv2d_transpose[0][0]',    \n",
            "                                                                     'activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 32, 32, 512)          4719104   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 64, 64, 256)          524544    ['activation_11[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 64, 64, 512)          0         ['conv2d_transpose_1[0][0]',  \n",
            " )                                                                   'activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 64, 64, 256)          1179904   ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 128, 128, 128)        131200    ['activation_13[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 128, 128, 256)        0         ['conv2d_transpose_2[0][0]',  \n",
            " )                                                                   'activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 128, 128, 128)        295040    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 256, 256, 64)         32832     ['activation_15[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 256, 256, 128)        0         ['conv2d_transpose_3[0][0]',  \n",
            " )                                                                   'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 256, 256, 64)         73792     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31055297 (118.47 MB)\n",
            "Trainable params: 31043521 (118.42 MB)\n",
            "Non-trainable params: 11776 (46.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions for Metrics"
      ],
      "metadata": {
        "id": "Rfdn6IuuOtmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "cmocn0fROsyr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Training on DATASET"
      ],
      "metadata": {
        "id": "saK4RO2VN_yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "e0Hlj6VtN1vl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Global parameters \"\"\"\n",
        "H = 256\n",
        "W = 256"
      ],
      "metadata": {
        "id": "SMo7kSwKOHs9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions to build a temp path and load dataset"
      ],
      "metadata": {
        "id": "FzBtQlOQPIJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_dataset(path, split=0.2):\n",
        "    images = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n",
        "    masks = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n",
        "\n",
        "    print(len(images))\n",
        "\n",
        "    train_x, valid_x = train_test_split(images, test_size=0.2, random_state=42)\n",
        "    train_y, valid_y = train_test_split(masks, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_x, test_x = train_test_split(train_x, test_size=0.25, random_state=42)\n",
        "    train_y, test_y = train_test_split(train_y, test_size=0.25, random_state=42)\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(10)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "CzuNunn2O_QL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading of Image and Mask from the dataset"
      ],
      "metadata": {
        "id": "sKnGJDUHPQX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x / 255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n",
        "    x = cv2.resize(x, (W, H))                   ## (h, w)\n",
        "    x = x / 255.0                               ## (h, w)\n",
        "    x = x.astype(np.float32)                    ## (h, w)\n",
        "    x = np.expand_dims(x, axis=-1)              ## (h, w, 1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "amINrugvPNUR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Directory for storing files \"\"\"\n",
        "create_dir(\"files\")\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 16\n",
        "lr = 1e-4\n",
        "num_epochs = 5\n",
        "model_path = os.path.join(\"files\", \"model.h5\")\n",
        "csv_path = os.path.join(\"files\", \"log.csv\")"
      ],
      "metadata": {
        "id": "oKU8HLV5PT31"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Dataset \"\"\"\n",
        "dataset_path = \"/content/drive/MyDrive/Major/dataset\"\n",
        "\n",
        "# (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
        "\n",
        "path = dataset_path\n",
        "split=0.2\n",
        "\n",
        "images = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n",
        "masks = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n",
        "\n",
        "print(len(images), len(masks))\n",
        "\n",
        "train_x, test_x = train_test_split(images, test_size=0.2, random_state=42)\n",
        "train_y, test_y = train_test_split(masks, test_size=0.2, random_state=42)\n",
        "\n",
        "train_x, valid_x = train_test_split(train_x, test_size=0.25, random_state=42)\n",
        "train_y, valid_y = train_test_split(train_y, test_size=0.25, random_state=42)\n"
      ],
      "metadata": {
        "id": "vitB3fFKvhX8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "1a87a01e-ff09-4f69-d3ae-44e622e8dea2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1550 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d2a2456c3e7e>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    }
  ]
}